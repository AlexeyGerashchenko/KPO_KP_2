# Микросервисное приложение для обработки текстовых файлов

Этот проект представляет собой бэкенд-систему, построенную на микросервисной архитектуре с использованием Golang, Gin и GORM. Система предназначена для загрузки, хранения, анализа текстовых файлов и получения результатов анализа, включая генерацию "облака слов".

## Архитектура системы

Система состоит из трех основных микросервисов и двух баз данных PostgreSQL:

1.  **API Gateway (`api_gateway`)**:
    *   Отвечает исключительно за маршрутизацию входящих HTTP-запросов от пользователя к соответствующим внутренним микросервисам.
    *   Не содержит бизнес-логики.
    *   Взаимодействует с `File Storing Service` и `File Analysis Service`.
    *   Порт по умолчанию: `8080`.

2.  **File Storing Service (`file_storing_service`)**:
    *   Отвечает за хранение метаданных файлов и самих файлов.
    *   Метаданные (ID, имя, местоположение) хранятся в базе данных PostgreSQL №1 (`file_storage_db`).
    *   Содержимое файлов (`.txt`) сохраняется в файловом хранилище №1 (директория `file_storage_1`, монтируемая в Docker).
    *   Предоставляет API для загрузки файла, получения файла по ID, получения списка всех файлов, а также внутренние эндпоинты для `File Analysis Service` для получения местоположения и содержимого файла.
    *   Порт по умолчанию: `8081`.
    *   Swagger: `http://localhost:8081/swagger/index.html`

3.  **File Analysis Service (`file_analysis_service`)**:
    *   Отвечает за проведение анализа текстовых файлов, хранение результатов анализа и их выдачу.
    *   При запросе на анализ:
        *   Проверяет, есть ли уже готовый результат в своей базе данных PostgreSQL №2 (`file_analysis_db`).
        *   Если нет, обращается к `File Storing Service` для получения содержимого файла.
        *   Анализирует файл: подсчитывает количество абзацев, слов, символов.
        *   Обращается к внешнему API `wordcloudapi.com` (в данном случае `https://quickchart.io/wordcloud`) для генерации изображения "облака слов".
        *   Сохраняет сгенерированное изображение в файловом хранилище №2 (директория `file_storage_2`, монтируемая в Docker).
        *   Сохраняет результаты анализа (включая ID файла и местоположение изображения облака слов) в БД №2.
    *   Предоставляет API для запроса анализа файла, получения результатов анализа (без изображения облака слов) и получения изображения облака слов по его местоположению.
    *   Порт по умолчанию: `8082`.
    *   Swagger: `http://localhost:8082/swagger/index.html`

### Базы данных:

*   **PostgreSQL DB №1 (`file_storage_db`)**: Используется `File Storing Service` для хранения метаинформации о файлах.
*   **PostgreSQL DB №2 (`file_analysis_db`)**: Используется `File Analysis Service` для хранения результатов анализа файлов.

### Файловые хранилища:

*   **File Storage №1 (`./file_storage_1`)**: Используется `File Storing Service` для хранения загруженных `.txt` файлов.
*   **File Storage №2 (`./file_storage_2`)**: Используется `File Analysis Service` для хранения сгенерированных изображений облаков слов.

## Пользовательские сценарии и API

Все запросы пользователя проходят через API Gateway.

### 1. Загрузка файла

*   **Endpoint**: `POST /upload`
*   **Описание**: Пользователь загружает `.txt` файл.
*   **Процесс**:
    1.  Запрос поступает в API Gateway.
    2.  API Gateway перенаправляет запрос в `File Storing Service`.
    3.  `File Storing Service` генерирует уникальный ID для файла, сохраняет файл в File Storage №1 и его метаданные (ID, имя, местоположение) в БД №1.
    4.  `File Storing Service` возвращает ID файла в API Gateway.
    5.  API Gateway возвращает ID файла пользователю.
*   **Валидация**: Проверяется расширение файла (должно быть `.txt`).

### 2. Анализ файла

*   **Запрос на анализ**:
    *   **Endpoint**: `POST /analysis/{file_id}`
    *   **Описание**: Пользователь запрашивает анализ файла по его ID.
    *   **Процесс**:
        1.  Запрос поступает в API Gateway.
        2.  API Gateway перенаправляет запрос в `File Analysis Service`.
        3.  `File Analysis Service` проверяет наличие ранее проведенного анализа для этого `file_id` в БД №2.
            *   Если найден, переходит к шагу 13 внутреннего процесса `File Analysis Service` (возврат результатов).
        4.  `File Analysis Service` обращается к `File Storing Service` (через его внутренний API), чтобы получить местоположение файла по `file_id`.
        5.  `File Storing Service` извлекает местоположение из БД №1.
        6.  `File Analysis Service` обращается к `File Storing Service` (через его внутренний API), чтобы получить содержимое файла по его местоположению.
        7.  `File Storing Service` читает файл из File Storage №1 и возвращает содержимое.
        8.  `File Analysis Service` анализирует текст: количество абзацев (разделитель - перенос строки), слов, символов (без пробелов).
        9.  `File Analysis Service` обращается к `https://quickchart.io/wordcloud` с текстом файла.
        10. API облака слов возвращает изображение.
        11. `File Analysis Service` сохраняет изображение в File Storage №2.
        12. `File Analysis Service` сохраняет результаты анализа (включая `file_id` и местоположение изображения) в БД №2.
        13. `File Analysis Service` (в данном случае, так как запрос `POST /analysis/{file_id}` инициирует анализ) возвращает статус `202 Accepted` через API Gateway пользователю, сигнализируя, что запрос принят к обработке. Сам результат анализа получается отдельным запросом.

*   **Получение результатов анализа**:
    *   **Endpoint**: `GET /analysis/results/{file_id}`
    *   **Описание**: Пользователь запрашивает результаты анализа файла (без изображения облака слов).
    *   **Процесс**:
        1.  Запрос поступает в API Gateway.
        2.  API Gateway перенаправляет запрос в `File Analysis Service`.
        3.  `File Analysis Service` извлекает результаты анализа из БД №2 по `file_id`.
        4.  `File Analysis Service` возвращает результаты (количество абзацев, слов, символов) в API Gateway.
        5.  API Gateway возвращает результаты пользователю.

### 3. Получение файла

*   **Endpoint**: `GET /files/{id}`
*   **Описание**: Пользователь запрашивает содержимое файла по его ID.
*   **Процесс**:
    1.  Запрос поступает в API Gateway.
    2.  API Gateway перенаправляет запрос в `File Storing Service`.
    3.  `File Storing Service` находит метаданные файла в БД №1 по `id`.
    4.  `File Storing Service` читает содержимое файла из File Storage №1 по найденному местоположению.
    5.  `File Storing Service` возвращает содержимое файла в API Gateway.
    6.  API Gateway возвращает содержимое файла пользователю.

### 4. Получение облака слов

*   **Endpoint**: `GET /analysis/wordclouds?location={image_location}`
*   **Описание**: Пользователь запрашивает изображение облака слов по его местоположению (полученному ранее из результатов анализа).
*   **Процесс**:
    1.  Запрос поступает в API Gateway.
    2.  API Gateway перенаправляет запрос в `File Analysis Service`.
    3.  `File Analysis Service` читает файл изображения из File Storage №2 по указанному `location`.
    4.  `File Analysis Service` возвращает изображение в API Gateway.
    5.  API Gateway возвращает изображение пользователю.

### Дополнительные эндпоинты (для удобства и отладки)

*   `GET /files`: Возвращает список всех файлов, загруженных в `File Storing Service` (ID, имя, местоположение).
*   `GET /analysis/results-all`: Возвращает список всех результатов анализа из `File Analysis Service` (включая `file_id` и `word_cloud_location`).

## Паттерны проектирования

При разработке были применены следующие подходы для структурирования кода:

1.  **Адаптер (Adapter)**:
    *   **Взаимодействие `File Analysis Service` с `File Storing Service`**: Реализовано через `FileStoringServiceAdapter` в пакете `pkg/adapters`. Этот адаптер инкапсулирует логику HTTP-запросов к внутренним эндпоинтам `File Storing Service`.
    *   **Взаимодействие с внешним API (`wordcloudapi.com`)**: Реализовано через `WordCloudAPIAdapter` в пакете `pkg/adapters`. Этот адаптер отвечает за формирование запроса и обработку ответа от API генерации облака слов.
    *   **Работа с базами данных**: Реализовано через `DBAdapter` в пакете `pkg/adapters`. Этот адаптер предоставляет унифицированный интерфейс для операций с БД (GORM), скрывая детали реализации от сервисного слоя.
    *   **Сохранение файлов на диск**: Реализовано через `FileStorageAdapter` в пакете `pkg/adapters`. Этот адаптер инкапсулирует логику сохранения и чтения файлов из файловой системы, что позволяет легко подменить реализацию хранения (например, на S3) в будущем.

## Технологии

*   **Язык программирования**: Golang 1.20
*   **Веб-фреймворк**: Gin
*   **ORM**: GORM
*   **Базы данных**: PostgreSQL (2 отдельных экземпляра)
*   **Контейнеризация**: Docker, Docker Compose
*   **Документация API**: Swagger (OpenAPI)

## Запуск проекта

1.  **Убедитесь, что Docker и Docker Compose установлены.**
2.  **Склонируйте репозиторий.**
3.  **В корневой директории проекта выполните команду:**
    ```bash
    docker-compose up --build
    ```
    Эта команда соберет образы для всех микросервисов, создаст и запустит контейнеры, включая базы данных.

    *   API Gateway будет доступен по адресу `http://localhost:8080`.
    *   File Storing Service Swagger: `http://localhost:8081/swagger/index.html`
    *   File Analysis Service Swagger: `http://localhost:8082/swagger/index.html`

4.  **Для остановки проекта выполните:**
    ```bash
    docker-compose down
    ```
    Для удаления томов (данных БД и сохраненных файлов) используйте `docker-compose down -v`.

## Генерация Swagger документации

Для генерации или обновления Swagger-документации после внесения изменений в аннотации кода:

1.  Установите `swag` CLI, если еще не установлен:
    ```bash
    go install github.com/swaggo/swag/cmd/swag@latest
    ```
    Убедитесь, что `$GOPATH/bin` (или `$HOME/go/bin`, если GOPATH не установлен явно) добавлен в ваш `PATH`.

2.  Для каждого сервиса (`api_gateway`, `file_storing_service`, `file_analysis_service`) перейдите в его директорию и выполните:
    ```bash
    # Например, для file_storing_service
    cd file_storing_service
    swag init -g main.go --output ./docs
    cd .. 
    # Повторите для других сервисов
    ```

## Важные замечания и детали реализации

*   **Уникальность файлов**: Система считает каждый загружаемый файл уникальным и присваивает ему новый ID, даже если содержимое идентично ранее загруженному файлу.
*   **Валидация файлов**: При загрузке проверяется, что файл имеет расширение `.txt`.
*   **Границы абзацев**: Перенос строки (`\n`) считается разделителем абзацев. При подсчете учитываются только непустые строки.
*   **Коммуникация между сервисами**: Осуществляется через REST (HTTP) запросы.
*   **Обработка ошибок**:
    *   API Gateway при недоступности одного из внутренних сервисов (например, если он упал или не отвечает) вернет ошибку `502 Bad Gateway` или аналогичную, указывающую на проблему с вышестоящим сервером.
    *   Внутренние сервисы обрабатывают ошибки от своих зависимостей (БД, файловые хранилища, внешние API) и возвращают соответствующие HTTP-статусы и сообщения об ошибках.
    *   Если генерация облака слов в `File Analysis Service` не удается (например, из-за недоступности внешнего API), анализ файла продолжается, а поле `WordCloudLocation` в результатах остается пустым. Ошибка логируется на сервере.
*   **Идентификаторы**: Для ID файлов используется UUID v4.
*   **Хранение файлов**: Пути к файлам в конфигурации Docker Compose (`FILE_STORAGE_PATH` для сервисов) указывают на директории внутри контейнеров, которые монтируются на хост-машину (`./file_storage_1` и `./file_storage_2` в корне проекта). Это позволяет сохранять файлы между перезапусками контейнеров.
*   **Асинхронный анализ**: Запрос на анализ файла (`POST /analysis/{file_id}`) в `File Analysis Service` спроектирован так, чтобы потенциально выполняться асинхронно. В текущей реализации он выполняется в горутине, и сервис сразу возвращает `202 Accepted`. В более сложной системе здесь могла бы использоваться очередь сообщений.

## Тестирование API

После запуска приложения, вы можете взаимодействовать с API следующими способами:

### Swagger документация

API Gateway предоставляет полную документацию всех эндпоинтов:
- **API Gateway**: http://localhost:8080/swagger/index.html

Также каждый сервис имеет свою собственную Swagger-документацию:
- **File Storing Service**: http://localhost:8081/swagger/index.html
- **File Analysis Service**: http://localhost:8082/swagger/index.html

### Основные эндпоинты API Gateway

1. **Загрузка файла**
   - POST http://localhost:8080/upload
   - С multipart формой, содержащей файл с ключом "file"

2. **Запрос анализа файла**
   - POST http://localhost:8080/analysis/{file_id}

3. **Получение результатов анализа**
   - GET http://localhost:8080/analysis/results/{file_id}

4. **Получение файла**
   - GET http://localhost:8080/files/{id}

5. **Получение облака слов**
   - GET http://localhost:8080/analysis/wordclouds?location={location}

## Обработка ошибок

Система обрабатывает различные типы ошибок:
- Недоступность отдельных микросервисов
- Некорректные входные данные
- Отсутствие запрашиваемых ресурсов

## Дополнительная информация

Проект демонстрирует принципы микросервисной архитектуры:
- Каждый микросервис имеет четко определенную зону ответственности
- Микросервисы взаимодействуют между собой через HTTP API
- Данные хранятся в PostgreSQL и файловых хранилищах
- API Gateway управляет маршрутизацией запросов
- Система масштабируема и отказоустойчива 